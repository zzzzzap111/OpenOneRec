# OpenOneRec é¡¹ç›®æ¡†æ¶ä¸æ‰§è¡Œæµç¨‹åˆ†æ

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

**OpenOneRec** æ˜¯ä¸€ä¸ªå¼€æºçš„ç”Ÿæˆå¼æ¨èç³»ç»Ÿæ¡†æ¶ï¼Œæ—¨åœ¨å¼¥åˆä¼ ç»Ÿæ¨èç³»ç»Ÿä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¹‹é—´çš„å·®è·ã€‚é¡¹ç›®æä¾›äº†å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€åŸºå‡†æµ‹è¯•å’Œé¢„è®­ç»ƒæ¨¡å‹ã€‚

### æ ¸å¿ƒè´¡çŒ®

1. **RecIF-Bench**ï¼šé¦–ä¸ªå…¨é¢çš„æ¨èæŒ‡ä»¤éµå¾ªåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å« 100M äº¤äº’æ•°æ®ï¼Œè¦†ç›– 200k ç”¨æˆ·å’Œå¤šä¸ªå¼‚æ„é¢†åŸŸï¼ˆçŸ­è§†é¢‘ã€å¹¿å‘Šã€å•†å“ï¼‰
2. **OneRec-Foundation Models**ï¼šåŸºäº Qwen3 æ¶æ„çš„æ¨èæ¨¡å‹ç³»åˆ—ï¼ˆ1.7B å’Œ 8B å‚æ•°ï¼‰
3. **å…¨æ ˆè®­ç»ƒæµç¨‹**ï¼šå¼€æºå®Œæ•´çš„æ•°æ®å¤„ç†ã€é¢„è®­ç»ƒå’Œåè®­ç»ƒæµç¨‹

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

### ç›®å½•ç»“æ„

```
OpenOneRec/
â”œâ”€â”€ pretrain/              # é¢„è®­ç»ƒæ¨¡å—
â”‚   â”œâ”€â”€ onerec_llm/        # æ ¸å¿ƒæ¨¡å‹å’Œè®­ç»ƒä»£ç 
â”‚   â”œâ”€â”€ recipes/           # è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ examples/          # è®­ç»ƒç¤ºä¾‹
â”œâ”€â”€ verl_rl/              # å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼ˆVeRLæ¡†æ¶ï¼‰
â”œâ”€â”€ verl_distillation/    # çŸ¥è¯†è’¸é¦æ¨¡å—
â”œâ”€â”€ data/                 # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ general_text/     # é€šç”¨æ–‡æœ¬æ•°æ®
â”‚   â””â”€â”€ onerec_data/      # æ¨èä¸šåŠ¡æ•°æ®
â””â”€â”€ benchmarks/           # è¯„ä¼°åŸºå‡†æµ‹è¯•
```

### æ ¸å¿ƒæ¨¡å—è¯´æ˜

#### 1. **pretrain/** - é¢„è®­ç»ƒæ¨¡å—
- **åŠŸèƒ½**ï¼šåŸºäº Qwen3 çš„ä¸¤é˜¶æ®µé¢„è®­ç»ƒå’Œ SFT
- **å…³é”®ç»„ä»¶**ï¼š
  - `onerec_llm/models/qwen3/`ï¼šQwen3 æ¨¡å‹å®ç°
  - `onerec_llm/data/`ï¼šæ•°æ®åŠ è½½å™¨
  - `recipes/train_qwen3.py`ï¼šä¸»è®­ç»ƒè„šæœ¬

#### 2. **verl_rl/** - å¼ºåŒ–å­¦ä¹ æ¨¡å—
- **åŠŸèƒ½**ï¼šåŸºäº VeRL æ¡†æ¶çš„ RL è®­ç»ƒ
- **æ”¯æŒç®—æ³•**ï¼šPPOã€GRPOã€DAPOã€GPG ç­‰
- **å…³é”®ç‰¹æ€§**ï¼šæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒã€å¤šç§å¥–åŠ±å‡½æ•°

#### 3. **verl_distillation/** - çŸ¥è¯†è’¸é¦æ¨¡å—
- **åŠŸèƒ½**ï¼šOn-policy è’¸é¦ï¼Œæ¢å¤é€šç”¨æ¨ç†èƒ½åŠ›
- **åº”ç”¨åœºæ™¯**ï¼šåœ¨ RL è®­ç»ƒåæ¢å¤æ¨¡å‹çš„é€šç”¨èƒ½åŠ›

#### 4. **data/** - æ•°æ®å¤„ç†æ¨¡å—
- **åŠŸèƒ½**ï¼šå°†åŸå§‹æ¨èæ•°æ®è½¬æ¢ä¸º LLM è®­ç»ƒæ ¼å¼
- **æ•°æ®æ ¼å¼**ï¼šParquet æ ¼å¼ï¼Œæ”¯æŒ Chat å’Œ Segments ä¸¤ç§æ ¼å¼

#### 5. **benchmarks/** - è¯„ä¼°åŸºå‡†
- **åŠŸèƒ½**ï¼šRecIF-Bench è¯„ä¼°æ¡†æ¶
- **ä»»åŠ¡ç±»å‹**ï¼š8 ä¸ªä»»åŠ¡ï¼Œ4 å±‚èƒ½åŠ›å±‚æ¬¡

## ğŸ”„ å®Œæ•´æ‰§è¡Œæµç¨‹

### é˜¶æ®µ 0ï¼šç¯å¢ƒå‡†å¤‡ä¸è¯è¡¨æ‰©å±•

#### 0.1 ç¯å¢ƒé…ç½®
```bash
cd pretrain
source set_env.sh
```

#### 0.2 Qwen3 è¯è¡¨æ‰©å±•
**ç›®çš„**ï¼šä¸ºæ¨èç³»ç»Ÿæ·»åŠ  Itemic Tokensï¼ˆå•†å“ ID ç¼–ç ï¼‰

```bash
# ç¼–è¾‘ scripts/expand_qwen3_vocab.sh
HF_MODEL_DIR=/path/to/Qwen3-1.7B
OUTPUT_MODEL_DIR=/path/to/Qwen3-1.7B_itemic
ITEMIC_LAYER_N=3
VOCAB_SIZE_PER_LAYER=8192

# æ‰§è¡Œæ‰©å±•
bash scripts/expand_qwen3_vocab.sh
```

**æ‰©å±•å†…å®¹**ï¼š
- æ·»åŠ æ–°çš„ itemic tokensï¼ˆå¦‚ `<s_a_340><s_b_6566><s_c_5603>`ï¼‰
- å°†è¯è¡¨å¤§å°å¯¹é½åˆ° 256 çš„å€æ•°
- åˆå§‹åŒ–æ–° token çš„ embedding æƒé‡

### é˜¶æ®µ 1ï¼šæ•°æ®å‡†å¤‡

#### 1.1 ä¸‹è½½æ•°æ®é›†
- é€šç”¨æ–‡æœ¬æ•°æ®ï¼š[OpenOneRec-General-Pretrain](https://huggingface.co/datasets/OpenOneRec/OpenOneRec-General-Pretrain)
- SFT æ•°æ®ï¼š[OpenOneRec-General-SFT](https://huggingface.co/datasets/OpenOneRec/OpenOneRec-General-SFT)
- æ¨èæ•°æ®ï¼š[OpenOneRec-RecIF](https://huggingface.co/datasets/OpenOneRec/OpenOneRec-RecIF)

#### 1.2 å¤„ç†æ¨èæ•°æ®
```bash
cd data/onerec_data
# ç¼–è¾‘ run.shï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
bash run.sh
```

**å¤„ç†ä»»åŠ¡**ï¼š
- **é¢„è®­ç»ƒæ•°æ®**ï¼š
  - `video_rec.py`ï¼šè§†é¢‘æ¨èæ•°æ®
  - `user_profile.py`ï¼šç”¨æˆ·ç”»åƒæ•°æ®
  - `item_understand.py`ï¼šå•†å“ç†è§£æ•°æ®
- **SFT æ•°æ®**ï¼š
  - `video_rec.py`ï¼šè§†é¢‘æ¨è
  - `ad_rec.py`ï¼šå¹¿å‘Šæ¨è
  - `product_rec.py`ï¼šå•†å“æ¨è
  - `interactive_rec.py`ï¼šäº¤äº’æ¨è
  - `label_cond_rec.py`ï¼šæ ‡ç­¾æ¡ä»¶æ¨è
  - `label_pred.py`ï¼šæ ‡ç­¾é¢„æµ‹
  - `rec_reason.py`ï¼šæ¨èè§£é‡Š

#### 1.3 æ•°æ®åˆ†ç‰‡å¤„ç†
```bash
# é¢„è®­ç»ƒæ•°æ®
bash data/prepare_pretrain.sh

# SFT æ•°æ®
bash data/prepare_sft.sh

# RL æ•°æ®
bash data/prepare_rl.sh

# Distillation æ•°æ®
bash data/prepare_distillation.sh
```

**æ•°æ®æ ¼å¼**ï¼šParquet æ ¼å¼ï¼Œæ¯ä¸ªæ–‡ä»¶çº¦ 1000 ä¸ªæ ·æœ¬

### é˜¶æ®µ 2ï¼šé¢„è®­ç»ƒï¼ˆPre-Trainingï¼‰

#### 2.1 Stage 1ï¼šItemic-Text Alignmentï¼ˆå¯¹é½é˜¶æ®µï¼‰

**ç›®æ ‡**ï¼šè®­ç»ƒ Itemic Token çš„ embeddingï¼Œå¯¹é½å•†å“è¡¨ç¤ºå’Œæ–‡æœ¬è¡¨ç¤º

```bash
bash pretrain/examples/pretrain_stg1.sh
```

**å…³é”®å‚æ•°**ï¼š
- `--freeze_llm`ï¼šå†»ç»“ LLM å‚æ•°ï¼Œåªè®­ç»ƒ embedding
- `--start_optimize_embedding_index 151669`ï¼šä» itemic token èµ·å§‹ ID å¼€å§‹ä¼˜åŒ–
- `--dataset_config examples/dataset_config/stg1.json`ï¼šStage1 æ•°æ®é…ç½®

**è®­ç»ƒå†…å®¹**ï¼š
- åœ¨æ¨èæ•°æ®ä¸Šè®­ç»ƒ itemic embedding
- å­¦ä¹ å•†å“ ID åˆ°è¯­ä¹‰ç©ºé—´çš„æ˜ å°„
- å»ºç«‹å•†å“å’Œæ–‡æœ¬ä¹‹é—´çš„å¯¹é½å…³ç³»

#### 2.2 Stage 2ï¼šFull-Parameter Co-Pretrainingï¼ˆå…¨å‚æ•°ååŒé¢„è®­ç»ƒï¼‰

**ç›®æ ‡**ï¼šåœ¨æ¨èæ•°æ®å’Œé€šç”¨æ–‡æœ¬æ•°æ®çš„æ··åˆåŸŸä¸Šè¿›è¡Œå…¨å‚æ•°è®­ç»ƒ

```bash
bash pretrain/examples/pretrain_stg2.sh
```

**å…³é”®å‚æ•°**ï¼š
- **ä¸åŒ…å«** `--freeze_llm`ï¼šå…¨å‚æ•°è®­ç»ƒ
- `--dataset_config examples/dataset_config/pretrain.json`ï¼šåŒ…å«æ¨èæ•°æ®å’Œé€šç”¨æ–‡æœ¬æ•°æ®
- `--model_dir`ï¼šæŒ‡å‘ Stage1 è¾“å‡ºçš„è½¬æ¢åçš„æ¨¡å‹

**è®­ç»ƒå†…å®¹**ï¼š
- æ··åˆæ¨èæ•°æ®å’Œé€šç”¨æ–‡æœ¬æ•°æ®
- å…¨å‚æ•°ä¼˜åŒ–ï¼Œæå‡æ¨¡å‹é€šç”¨èƒ½åŠ›
- ä¿æŒæ¨èèƒ½åŠ›çš„åŒæ—¶å¢å¼ºè¯­è¨€ç†è§£èƒ½åŠ›

**æ¨¡å‹è½¬æ¢**ï¼š
```bash
# å°†è®­ç»ƒ checkpoint è½¬æ¢ä¸º HuggingFace æ ¼å¼
bash pretrain/scripts/convert_checkpoint_to_hf.sh \
    <base_model_dir> <model_home> <step>
```

### é˜¶æ®µ 3ï¼šåè®­ç»ƒï¼ˆPost-Trainingï¼‰

#### 3.1 Stage 1ï¼šSupervised Fine-Tuning (SFT)

**ç›®æ ‡**ï¼šå¤šä»»åŠ¡ç›‘ç£å¾®è°ƒï¼Œæå‡æŒ‡ä»¤éµå¾ªèƒ½åŠ›

```bash
bash pretrain/examples/posttrain_sft.sh
```

**å…³é”®å‚æ•°**ï¼š
- `--dataset_config examples/dataset_config/sft.json`ï¼šSFT æ•°æ®é…ç½®
- `--model_dir`ï¼šStage2 è¾“å‡ºçš„è½¬æ¢åçš„æ¨¡å‹
- `add_think_pattern: true`ï¼šå¯ç”¨ thinking æ¨¡å¼ï¼ˆç”¨äºæ¨ç†ä»»åŠ¡ï¼‰

**è®­ç»ƒå†…å®¹**ï¼š
- åœ¨ 8 ä¸ª RecIF-Bench ä»»åŠ¡ä¸Šè¿›è¡Œå¤šä»»åŠ¡å­¦ä¹ 
- å­¦ä¹ æŒ‡ä»¤éµå¾ªå’Œæ¨èä»»åŠ¡æ‰§è¡Œ
- æ”¯æŒ thinking æ¨¡å¼ï¼ˆ`<think>` æ ‡ç­¾ï¼‰

#### 3.2 Stage 2ï¼šOn-Policy Distillationï¼ˆç­–ç•¥è’¸é¦ï¼‰

**ç›®æ ‡**ï¼šæ¢å¤æ¨¡å‹çš„é€šç”¨æ¨ç†èƒ½åŠ›ï¼Œé¿å…è¿‡åº¦ç‰¹åŒ–

**ä½¿ç”¨æ¨¡å—**ï¼š`verl_distillation/`

**è®­ç»ƒå†…å®¹**ï¼š
- åœ¨é€šç”¨æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œ on-policy è’¸é¦
- ä¿æŒæ¨èèƒ½åŠ›çš„åŒæ—¶æ¢å¤é€šç”¨èƒ½åŠ›
- å¹³è¡¡æ¨èæ€§èƒ½å’Œé€šç”¨è¯­è¨€èƒ½åŠ›

#### 3.3 Stage 3ï¼šReinforcement Learning (RL)

**ç›®æ ‡**ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨èæ€§èƒ½

**ä½¿ç”¨æ¨¡å—**ï¼š`verl_rl/`

**æ”¯æŒçš„ç®—æ³•**ï¼š
- **PPO**ï¼šProximal Policy Optimization
- **GRPO**ï¼šGroup Relative Policy Optimization
- **DAPO**ï¼šDirect Alignment Policy Optimization
- **GPG**ï¼šGroup Preference Optimization

**è®­ç»ƒæµç¨‹**ï¼š
1. ä½¿ç”¨ SFT æ¨¡å‹ä½œä¸ºåˆå§‹ç­–ç•¥
2. ç”Ÿæˆå€™é€‰æ¨è
3. è®¡ç®—å¥–åŠ±ï¼ˆåŸºäºæ¨èè´¨é‡ï¼‰
4. ä½¿ç”¨ RL ç®—æ³•ä¼˜åŒ–ç­–ç•¥

**å…³é”®é…ç½®**ï¼š
- å¥–åŠ±å‡½æ•°ï¼šåŸºäºæ¨èå‡†ç¡®æ€§ã€å¤šæ ·æ€§ç­‰æŒ‡æ ‡
- çº¦æŸè§£ç ï¼šç¡®ä¿ç”Ÿæˆçš„ itemic tokens æœ‰æ•ˆ
- å¤šä»»åŠ¡è®­ç»ƒï¼šåœ¨å¤šä¸ªæ¨èä»»åŠ¡ä¸ŠåŒæ—¶ä¼˜åŒ–

## ğŸ¯ æ ¸å¿ƒæŠ€æœ¯ç‚¹

### 1. Itemic Tokensï¼ˆå•†å“ Tokenï¼‰

**æ¦‚å¿µ**ï¼šå°†å•†å“è¡¨ç¤ºä¸ºç‰¹æ®Šçš„ tokenï¼Œé€šè¿‡åˆ†å±‚å‘é‡é‡åŒ–ç”Ÿæˆ

**æ ¼å¼**ï¼š
```
<|sid_begin|><s_a_340><s_b_6566><s_c_5603><|sid_end|>
```

**ä¼˜åŠ¿**ï¼š
- å°†å•†å“ä½œä¸ºç‹¬ç«‹æ¨¡æ€å¤„ç†
- å…è®¸ LLM å°†äº¤äº’å†å²ä½œä¸ºè¿è´¯çš„ä¸Šä¸‹æ–‡åºåˆ—
- æ”¯æŒå•†å“å’Œæ–‡æœ¬çš„ç»Ÿä¸€è¡¨ç¤º

### 2. å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥

```
è¯è¡¨æ‰©å±• â†’ Stage1é¢„è®­ç»ƒ â†’ Stage2é¢„è®­ç»ƒ â†’ SFT â†’ Distillation â†’ RL
```

**è®¾è®¡ç†å¿µ**ï¼š
- **æ¸è¿›å¼è®­ç»ƒ**ï¼šä»å¯¹é½åˆ°å…¨å‚æ•°ï¼Œä»ç›‘ç£åˆ°å¼ºåŒ–å­¦ä¹ 
- **èƒ½åŠ›å¹³è¡¡**ï¼šé€šè¿‡è’¸é¦ä¿æŒé€šç”¨èƒ½åŠ›
- **ä»»åŠ¡ç‰¹åŒ–**ï¼šé€šè¿‡ RL ä¼˜åŒ–æ¨èæ€§èƒ½

### 3. RecIF-Bench å››å±‚èƒ½åŠ›ä½“ç³»

| å±‚çº§ | èƒ½åŠ› | ä»»åŠ¡ |
|------|------|------|
| **Layer 0** | è¯­ä¹‰å¯¹é½ | å•†å“ç†è§£ |
| **Layer 1** | åŸºç¡€é¢„æµ‹ | è§†é¢‘æ¨èã€å¹¿å‘Šæ¨èã€å•†å“æ¨èã€æ ‡ç­¾é¢„æµ‹ |
| **Layer 2** | æŒ‡ä»¤éµå¾ª | äº¤äº’æ¨èã€æ ‡ç­¾æ¡ä»¶æ¨è |
| **Layer 3** | æ¨ç†èƒ½åŠ› | æ¨èè§£é‡Š |

### 4. æ•°æ®æ ¼å¼è§„èŒƒ

**Parquet æ ¼å¼å­—æ®µ**ï¼š
- `uuid`ï¼šå”¯ä¸€æ ‡è¯†ç¬¦
- `source`ï¼šæ•°æ®æ¥æº
- `messages`ï¼šå¯¹è¯æ ¼å¼ï¼ˆChatï¼‰
- `segments`ï¼šæ®µè½æ ¼å¼ï¼ˆSegmentsï¼‰
- `text`ï¼šçº¯æ–‡æœ¬
- `metadata`ï¼šå…ƒæ•°æ®ï¼ˆJSON å­—ç¬¦ä¸²ï¼‰

**ä¸¤ç§ä¸»è¦æ ¼å¼**ï¼š
1. **Chat æ ¼å¼**ï¼šç”¨äºå¯¹è¯æ•°æ®
2. **Segments æ ¼å¼**ï¼šç”¨äºæ™®é€šæ–‡æœ¬æ•°æ®

## ğŸ“Š è®­ç»ƒé…ç½®è¯´æ˜

### æ•°æ®é…ç½®æ–‡ä»¶æ ¼å¼

```json
{
    "name": "chat_completion_parquet",
    "sources": "/path/to/data_list.json",
    "base_model_dir": "/path/to/Qwen3-1.7B_itemic",
    "max_length": 30000,
    "num_epochs": 3,
    "num_workers": 2,
    "itemic_id_range": [151669, 176246],
    "add_think_pattern": false,
    "local_shuffle_buffer_size": 100000
}
```

### è®­ç»ƒå‚æ•°

**é¢„è®­ç»ƒå‚æ•°**ï¼š
- `--model_dir`ï¼šåŸºç¡€æ¨¡å‹è·¯å¾„
- `--output_dir`ï¼šè¾“å‡ºç›®å½•
- `--dataset_config`ï¼šæ•°æ®é…ç½®æ–‡ä»¶
- `--freeze_llm`ï¼šæ˜¯å¦å†»ç»“ LLMï¼ˆStage1 ä½¿ç”¨ï¼‰
- `--max_length`ï¼šæœ€å¤§åºåˆ—é•¿åº¦ï¼ˆ32768ï¼‰
- `--learning_rate`ï¼šå­¦ä¹ ç‡ï¼ˆ2e-4ï¼‰
- `--num_training_steps`ï¼šè®­ç»ƒæ­¥æ•°

**SFT å‚æ•°**ï¼š
- `--dataset_config`ï¼šSFT æ•°æ®é…ç½®
- `--add_think_pattern`ï¼šæ˜¯å¦å¯ç”¨ thinking æ¨¡å¼
- `--only_assistant_loss`ï¼šæ˜¯å¦åªè®¡ç®— assistant å“åº”æŸå¤±

## ğŸ”§ å·¥å…·è„šæœ¬

### æ¨¡å‹è½¬æ¢
```bash
bash pretrain/scripts/convert_checkpoint_to_hf.sh \
    <base_model_dir> <model_home> <step>
```

### æ¨¡å‹æµ‹è¯•
```bash
bash pretrain/scripts/test_hf_model.sh <hf_model_dir>
```

### è®­ç»ƒç›‘æ§
- TensorBoardï¼š`tensorboard --logdir=$OUTPUT_DIR`
- æ—¥å¿—æ–‡ä»¶ï¼š`$OUTPUT_DIR/stdout.log` å’Œ `$OUTPUT_DIR/stderr.log`

## ğŸš€ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

### å®Œæ•´è®­ç»ƒæµç¨‹

```bash
# 1. è¯è¡¨æ‰©å±•
cd pretrain
bash scripts/expand_qwen3_vocab.sh

# 2. æ•°æ®å‡†å¤‡
cd ../data
bash onerec_data/run.sh
bash prepare_pretrain.sh
bash prepare_sft.sh

# 3. Stage1 é¢„è®­ç»ƒ
cd ../pretrain
bash examples/pretrain_stg1.sh

# 4. æ¨¡å‹è½¬æ¢
bash scripts/convert_checkpoint_to_hf.sh \
    ./qwen_extended ./output/stg1 2000

# 5. Stage2 é¢„è®­ç»ƒ
bash examples/pretrain_stg2.sh

# 6. æ¨¡å‹è½¬æ¢
bash scripts/convert_checkpoint_to_hf.sh \
    ./qwen_extended ./output/stg2 5000

# 7. SFT
bash examples/posttrain_sft.sh

# 8. Distillationï¼ˆå¯é€‰ï¼‰
cd ../verl_distillation
# è¿è¡Œè’¸é¦è„šæœ¬

# 9. RLï¼ˆå¯é€‰ï¼‰
cd ../verl_rl
# è¿è¡Œ RL è®­ç»ƒè„šæœ¬
```

## ğŸ“ˆ æ€§èƒ½è¡¨ç°

### RecIF-Bench ç»“æœ

OneRec-8B-Pro åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ° SOTAï¼š
- **Short Video Rec**ï¼šRecall@32 = 0.0369
- **Ad Rec**ï¼šRecall@32 = 0.0964
- **Product Rec**ï¼šRecall@32 = 0.0538
- **Interactive Rec**ï¼šRecall@32 = 0.3458
- **Rec. Explanation**ï¼šLLM Score = 4.0381

### è·¨åŸŸè¿ç§»èƒ½åŠ›

åœ¨ Amazon Benchmarkï¼ˆ10 ä¸ªæ•°æ®é›†ï¼‰ä¸Šï¼Œå¹³å‡ Recall@10 æå‡ **26.8%**

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **MPI ç¯å¢ƒ**ï¼š
   - é¢„è®­ç»ƒæ¨¡å—ä¾èµ– MPIï¼ˆOpenMPIï¼‰
   - éœ€è¦é…ç½® hostfile
   - ç¡®ä¿èŠ‚ç‚¹é—´ SSH æ— å¯†ç è®¿é—®

2. **æ•°æ®æ ¼å¼**ï¼š
   - å¿…é¡»ä½¿ç”¨ Parquet æ ¼å¼
   - æ¯ä¸ªæ–‡ä»¶å»ºè®® 1000 ä¸ªæ ·æœ¬
   - ç¡®ä¿æ•°æ®ç¬¦åˆæ ¼å¼è§„èŒƒ

3. **æ¨¡å‹å¤§å°**ï¼š
   - 0.6B/1.7B/4B æ¨¡å‹éœ€è¦ `--use_tie_weights`
   - ä¸åŒæ¨¡å‹å¤§å°éœ€è¦ä¸åŒçš„å­¦ä¹ ç‡é…ç½®

4. **è¯è¡¨æ‰©å±•**ï¼š
   - è®­ç»ƒå‰å¿…é¡»å…ˆæ‰©å±•è¯è¡¨
   - ç¡®ä¿ `itemic_id_range` ä¸æ‰©å±•é…ç½®ä¸€è‡´

## ğŸ”— ç›¸å…³èµ„æº

- **æ¨¡å‹ä¸‹è½½**ï¼š[HuggingFace OpenOneRec](https://huggingface.co/OpenOneRec)
- **æ•°æ®é›†**ï¼š[RecIF-Bench](https://huggingface.co/datasets/OpenOneRec/OpenOneRec-RecIF)
- **è®ºæ–‡**ï¼š[arXiv:2512.24762](https://arxiv.org/abs/2512.24762)

## ğŸ“ æ€»ç»“

OpenOneRec æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„ç”Ÿæˆå¼æ¨èç³»ç»Ÿæ¡†æ¶ï¼Œé€šè¿‡ï¼š

1. **Itemic Tokens**ï¼šå°†å•†å“ä½œä¸ºç‰¹æ®Š tokenï¼Œå®ç°æ¨¡æ€å¯¹é½
2. **å¤šé˜¶æ®µè®­ç»ƒ**ï¼šä»å¯¹é½åˆ°å…¨å‚æ•°ï¼Œä»ç›‘ç£åˆ°å¼ºåŒ–å­¦ä¹ 
3. **èƒ½åŠ›å¹³è¡¡**ï¼šé€šè¿‡è’¸é¦ä¿æŒé€šç”¨èƒ½åŠ›
4. **å…¨é¢è¯„ä¼°**ï¼šRecIF-Bench æä¾›å¤šå±‚æ¬¡çš„è¯„ä¼°ä½“ç³»

è¯¥æ¡†æ¶ä¸ºç”Ÿæˆå¼æ¨èç³»ç»Ÿçš„ç ”ç©¶å’Œåº”ç”¨æä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚

